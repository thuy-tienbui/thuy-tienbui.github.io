[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A lifelong Californian, I grew up in Orange County and moved to the Bay Area to attend UC Berkeley and frolic among the redwoods. After graduating with a degree in Conservation and Resource Studies, I traveled down the coast to sunny Santa Barbara, where I am completing my Master of Environmental Science and Management at UCSB’s Bren School. I am a passionate naturalist and ecologist, excited about collaborative land stewardship, native plants, and maps.\n\nPhotosEducation & CertificationsSkillsets\n\n\n\n\n\n\n\n\n\n\n\nInstalling soil moisture data loggers with my field team\n\n\n\n\n\n\n\nHelping out with fuels reduction at Russell Research Station\n\n\n\n\n\n\n\nTesting burn box experiements with a PhD student at Sedgwick Reserve\n\n\n\n\n\n\n\n\n\nKnee deep in ice plant conducting vegetation surveys for NASA’s SHIFT campaign at the Jack and Laura Dangermond Preserve\n\n\n\n\n\n\n\nPrescribed fire TREX at Sedgwick Reserve\n\n\n\n\n\n\n\nObserving a tree felling demonstration by members of the Forestry and Fire Recruitment Program (FFRP)\n\n\n\n\n\n\n\n\n\nMe next to a Sequoiadendron giganteum circa 2006\n\n\n\n\n\n\n\nSetting a bucking saw for a logging demo\n\n\n\n\n\n\n\nTeaching my field class about herpetology\n\n\n\n\n\n\n\n\nEducation\nMaster of Environmental Science and Management\n\nUniversity of California, Santa Barbara\n\nBachelor of Science, Conservation and Resource Studies\n\nUniversity of California, Berkeley\n\n\n\nCertifications\n\nNOLS Wilderness/Remote Location First Aid\nNASA ARSET Invasive Species Monitoring with Remote Sensing\nNASA ARSET Drought Monitoring, Prediction, and Projection with NASA Earth System Data\nS-190 Wildland Fire Behavior, National Wildfire Coordinating Group\n\n\n\n\nData Analysis & Visualization\nR/R Studio, GitHub, ggplot, Leaflet, Shiny, Wallace, prioritizr, bipartite\nGeospatial Analysis & Remote Sensing\nR, ArcGIS Pro, ArcGIS Online, Google Earth Engine, QGIS\nFieldwork\nCoastal sage scrub plant identification, eDNA collection, insect rearing and net trapping, UTV operation, chainsaw operation and safety"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thuy-Tien Bui",
    "section": "",
    "text": "Welcome!\nI am a broadly trained ecologist and science communicator that leverages spatial data science to support conservation and management efforts. Some of my recent projects and experiences are highlighted on this website. Feel free to explore and get in touch!\n\n\nProfessional Interests\nLandscape ecology | Fire ecology | Geographic Information Systems | Remote Sensing | Climate Resiliency | Habitat Restoration | Collaborative Stewardship\n\n\nRecent Works\nEvaluating Ecological Conservation Gaps Across a Proposed Sentinel Landscape\nWildlife Connectivity Across the Central California Coast Region\nCoyote Watershed Management Plan"
  },
  {
    "objectID": "projects/2025-02-14-palmetto/index.html",
    "href": "projects/2025-02-14-palmetto/index.html",
    "title": "Classifying plant species using binary logistic regression",
    "section": "",
    "text": "Dataset and Analysis Overview\nThe dataset analyzed in this study details survival, growth, and biomass estimates of two dominant palmetto species (Serenoa repens and Sabal etonia) of south-central Florida from 1981-2017. Height, canopy length and width (cm), and number of new and green leaves were measured annually from 1981-1997 and again from 2001-2017.\nThe purpose of this analysis is to use a binary logistic regression to test whether measurements of height, canopy length, canopy width, and number of green leaves can be used to determine the species of an unknown palmetto plant.\nData Citation: Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative.\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(here)\nlibrary(cowplot)\nlibrary(patchwork)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(DiagrammeR)\n\n#create table outlining pseudocode\npseudo_df &lt;- data.frame(\n  Steps = c(\"Read in and clean data\", \n                  \"Create boxplots to compare distribution of variables for each species\", \n                  \"Define two model formulas with different variable inclusions\", \n                  \"Fit models using ten fold cross validation\", \n                  \"Compare the models' predictive performance to select the best model\", \n                  \"Train the selected model on the entire dataset\",\n                  \"Obtain finalized parameter results\",\n                  \"Generate species predictions from best model\",\n                  \"Calculate prediction accuracy for each species\"))\n\npseudo_df %&gt;% kable(\"html\", escape = FALSE) %&gt;%\n  kable_styling(bootstrap_options = c(\"hover\")) %&gt;%\n  pack_rows(\"1. Explore Data\", 1, 2) %&gt;%\n  pack_rows(\"2. Compare binary logistic models\", 3, 5) %&gt;%\n  pack_rows(\"3. Train the selected model\", 6, 7) %&gt;% \n  pack_rows(\"4. Classification results\", 8, 9)\n\n\n\n\n\nSteps\n\n\n\n\n1. Explore Data\n\n\nRead in and clean data\n\n\nCreate boxplots to compare distribution of variables for each species\n\n\n2. Compare binary logistic models\n\n\nDefine two model formulas with different variable inclusions\n\n\nFit models using ten fold cross validation\n\n\nCompare the models' predictive performance to select the best model\n\n\n3. Train the selected model\n\n\nTrain the selected model on the entire dataset\n\n\nObtain finalized parameter results\n\n\n4. Classification results\n\n\nGenerate species predictions from best model\n\n\nCalculate prediction accuracy for each species\n\n\n\n\n\n\n\n\n\nData Visualization\nI aim to assess whether height, width, length, and the number of green leaves can serve as effective variables for distinguishing between the two species. For these variables to be useful predictors, there should be clear and significant differences in their values between the species. To explore this, I will use boxplots, which provide a visual way to compare the distributions of these variables for each species and identify any noteworthy variations.\n\n\nCode\n#read in dataset\npalmetto_df &lt;- read_csv(here(\"data\", \"palmetto.csv\"))\n\n#remove unnecessary columns and change species data type to factor\npalmetto_clean &lt;- palmetto_df %&gt;% \n  select(species, height:green_lvs) %&gt;% \n  mutate(species = as_factor(species)) %&gt;% \n  drop_na()\n\n#explore the focal variables across the two species using boxplots\nheight_plot &lt;- ggplot(palmetto_clean, aes(x = as_factor(species), y = height)) + \n  geom_boxplot(fill = \"#AEAC4C\", \n               color = \"#778F33\",\n               alpha = 0.7, \n               outlier.color = \"#E8851D\") +\n  scale_x_discrete(labels = c(\"1\" = \"Serenoa repens\", \"2\" = \"Sabal etonia\")) +\n  labs(x = \"\", y = \"Canopy Height (cm)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(face = \"italic\")) + \n  theme(plot.margin = margin(20, 20, 20, 20))\n\nlength_plot &lt;- ggplot(palmetto_clean, aes(x = as_factor(species), y=length)) +\n  geom_boxplot(fill = \"#AEAC4C\", \n               color = \"#778F33\",\n               alpha = 0.7, \n               outlier.color = \"#E8851D\") +\n  scale_x_discrete(labels = c(\"1\" = \"Serenoa repens\", \"2\" = \"Sabal etonia\")) +\n  labs(x = \"\", y = \"Canopy Length (cm)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(face = \"italic\")) + \n  theme(plot.margin = margin(20, 20, 20, 20))\n\nwidth_plot &lt;- ggplot(palmetto_clean, aes(x = as_factor(species), y=width)) +\n  geom_boxplot(fill = \"#AEAC4C\", \n               color = \"#778F33\",\n               alpha = 0.7, \n               outlier.color = \"#E8851D\") +\n  scale_x_discrete(labels = c(\"1\" = \"Serenoa repens\", \"2\" = \"Sabal etonia\")) +\n  labs(x = \"\", y = \"Canopy Width (cm)\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(face = \"italic\")) + \n  theme(plot.margin = margin(20, 20, 20, 20))\n\nleaves_plot &lt;- ggplot(palmetto_clean, aes(x = as_factor(species), y=green_lvs)) +\n  geom_boxplot(fill = \"#AEAC4C\", \n               color = \"#778F33\",\n               alpha = 0.7, \n               outlier.color = \"#E8851D\") +\n  scale_x_discrete(labels = c(\"1\" = \"Serenoa repens\", \"2\" = \"Sabal etonia\")) +\n  labs(x = \"\", y = \"Count of Green Leaves\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(face = \"italic\")) + \n  theme(plot.margin = margin(20, 20, 20, 20))\n\n\n\n\nCode\n#combine above plots in a single output panel format\n#| label: fig-variables\n#| fig-cap: \"Comparison of canopy height, canopy width, canopy length, and count of green leaves for *Serenoa repens* and *Sabal etonia.*\"\n\nplot_grid(height_plot, length_plot, width_plot, leaves_plot,\n          labels = c(\"A\", \"B\", \"C\", \"D\"),\n          ncol = 2,\n          label_x=0.01,\n          label_y = 0.98)\n\n\n\n\n\n\n\n\n\n\nThe plant heights of the two species appear to be similar, suggesting that height may not be a strong predictor for species identification. However, there are noticeable differences in plant width, with greater distinctions in leaf length and the number of green leaves. Leaf length and the number of green leaves will be particularly significant predictors, as they appear to exhibit the most considerable variation between the species.\n\n\n\nBinary Logistic Regression Models\nI compared two models: one that predicts species based on height, width, and green leaves, and one that predicts species based on height, width, green leaves, and length. I assessed model performance by repeatedly fitting the model to ten different subsets of the data (ten-fold cross validation) and evaluating the performance metrics.\n\nModel 1 - log odds of plant type using plant height, canopy length, canopy width and green leaves as predictor variables.\nModel 2 - Log odds of plant type using plant height, canopy width and green leaves as predictor variables.\n\n\n\nCode\n#define formulas\nf1 &lt;- species ~ height  + width + green_lvs + length\nf2 &lt;- species ~ height + width + green_lvs\n\n#create folds\nset.seed(123)\nfolds &lt;- vfold_cv(palmetto_clean, v = 10, repeats = 10)\n\n#set up model\nblog_mdl &lt;- logistic_reg() %&gt;% \n  set_engine('glm')\n\n#create workflows\nblog_wf1 &lt;- workflow() %&gt;%\n  add_model(blog_mdl) %&gt;% \n  add_formula(f1)\n\nblog_wf2 &lt;- workflow() %&gt;%\n  add_model(blog_mdl) %&gt;% \n  add_formula(f2)\n\n#apply workflows to folded data\nblog_fit_folds1 &lt;- blog_wf1 %&gt;% \n  fit_resamples(folds)\n  \nblog_fit_folds2 &lt;- blog_wf2 %&gt;% \n  fit_resamples(folds)\n\n#cross validation results\ncollect_metrics(blog_fit_folds1) %&gt;% \n  select(-.config) %&gt;% \n  rename(metric = .metric,\n         estimator = .estimator,\n         standard_error = std_err) %&gt;% \n  kbl() %&gt;% \n  kable_styling(bootstrap_options = c(\"hover\"),\n                position = \"right\")\n\n\n\n\n\nmetric\nestimator\nmean\nn\nstandard_error\n\n\n\n\naccuracy\nbinary\n0.9168175\n100\n0.0007854\n\n\nbrier_class\nbinary\n0.0628770\n100\n0.0004686\n\n\nroc_auc\nbinary\n0.9724926\n100\n0.0003756\n\n\n\n\n\n\n\nCode\ncollect_metrics(blog_fit_folds2) %&gt;% \n  select(-.config) %&gt;% \n  rename(metric = .metric,\n         estimator = .estimator,\n         standard_error = std_err) %&gt;% \n  kbl() %&gt;% \n  kable_styling(bootstrap_options = c(\"hover\"),\n                position = \"right\")\n\n\n\n\n\nmetric\nestimator\nmean\nn\nstandard_error\n\n\n\n\naccuracy\nbinary\n0.8987528\n100\n0.0009137\n\n\nbrier_class\nbinary\n0.0735265\n100\n0.0004935\n\n\nroc_auc\nbinary\n0.9634662\n100\n0.0004368\n\n\n\n\n\n\n\n\nBoth models performed well based on their accuracy rates and area under the Receiver Operator Characteristic curve (ROC AUC). The cross validation results indicate model 1 (which includes length as a variable) is the best model for predicting species. This model had a greater ROC AUC and accuracy rate compared to model 2 (without length as a variable). Therefore, model 1 will be selected as the “best” model.\n\n\n\nTraining the selected model\nI trained model 1 on the entire dataset, without folding, to obtain the regression coefficients for each predictor variable.\n\n\nCode\n#train model on entire dataset\nblog1_fit &lt;- blog_mdl %&gt;%\n  fit(formula = f1, data = palmetto_clean)\n\n#create a table of the results\nbroom::tidy(blog1_fit) %&gt;% \n  select(-statistic) %&gt;% \n  kbl() %&gt;% \n  kable_styling(bootstrap_options = c(\"hover\"),\n                position = \"right\")\n\n\n\n\n\nterm\nestimate\nstd.error\np.value\n\n\n\n\n(Intercept)\n3.2266851\n0.1420708\n0\n\n\nheight\n-0.0292173\n0.0023061\n0\n\n\nwidth\n0.0394434\n0.0021000\n0\n\n\ngreen_lvs\n-1.9084747\n0.0388634\n0\n\n\nlength\n0.0458233\n0.0018661\n0\n\n\n\n\n\n\n\n\n\nEvaluating the trained model\nI evaluated the predictive strength of the finalized model, I compared the predicted species classifications to the actual species classifications. The predictions were already made using a 50% cutoff in which a species was classified as species 1 or 2 if the modeled probability of it being either species was 50% or greater.\n\n\nCode\nblog1_predict &lt;- palmetto_clean %&gt;% \n  mutate(predict(blog1_fit, new_data = .)) %&gt;% \n  mutate(predict(blog1_fit, new_data = ., type = 'prob'))\n\npredict_table &lt;- table(blog1_predict %&gt;%\n        select(species, .pred_class))\n\n\n\n\nCode\nkbl(data.frame(\n  species = c(\"1\", \"2\"),\n  n_correct = c(5548, 5701),\n  n_incorrect = c(564, 454)) %&gt;% \n  mutate(p_correct = n_correct/(n_correct+n_incorrect))) %&gt;%\n  kable_styling(bootstrap_options = c(\"hover\"),\n                position = \"right\")\n\n\n\n\nTable 1: Add figure caption\n\n\n\n\n\n\nspecies\nn_correct\nn_incorrect\np_correct\n\n\n\n\n1\n5548\n564\n0.9077225\n\n\n2\n5701\n454\n0.9262388\n\n\n\n\n\n\n\n\n\n\n\nModel 1 correctly classified palmetto as species 1 about 91% of the time and as species 2 93% of the time. The model is not completely precise, as some misclassifications still result, but it did demonstrate a high level of accuracy. The model’s performance could be enhanced by adding stronger predictive variables that better capture the differences between the species."
  },
  {
    "objectID": "projects/2025-03-01-randomforest/index.html",
    "href": "projects/2025-03-01-randomforest/index.html",
    "title": "Predicting forest burn area using random forests",
    "section": "",
    "text": "Introduction to the dataset\nThis analysis utilizes meteorological and fire-related data collected from forest fire incidents in the northeast region of Portugal. Key environmental variables include temperature, wind speed, relative humidity, and precipitation, which are known to influence fire behavior. Additionally, the dataset incorporates fire danger ratings from the Canadian Forest Fire Weather Index (FWI) system, which includes components such as the Fine Fuel Moisture Code (FFMC), Duff Moisture Code (DMC), Drought Code (DC), Initial Spread Index (ISI), Buildup Index (BUI), and the overall FWI score. These indices account for fuel moisture, fire spread potential, and fire intensity, incorporating past weather conditions to estimate fire behavior. By leveraging these meteorological and fire danger indicators, the dataset provides a robust foundation for modeling and predicting burn area using machine learning techniques.\nData Citation: Cortez, P., & Raimundo Morais, A. de J. (2007). A data mining approach to predict forest fires using meteorological data. Associação Portuguesa Para a Inteligência Artificial (APPIA).\n\n\nCode\nlibrary(tidyverse) \nlibrary(janitor)\nlibrary(dplyr)\nlibrary(tidymodels)\nlibrary(ggcorrplot)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ranger)\nlibrary(here)\nlibrary(ggplot2)\nlibrary(yardstick)\nlibrary(vip)\n\n\n\n\nPurpose\nThe objective of this analysis is to develop and tune a regression Random Forest model to predict the extent of forest area burned based on STFWI variables (spatial, temporal and the four FWI components). By leveraging meteorological and environmental variables, this study aims to identify key factors influencing fire spread and improve forecasting accuracy. Accurate predictions of burn area can assist in resource allocation for firefighting efforts, prioritizing response strategies, and mitigating the environmental and economic impacts of forest fires.\n\n\nData exploration\n\n\nCode\n# Load the data and convert the spatial and temporal variables to factors. Log(x+1) transform the burned hectares data\nforest &lt;- read_csv(here(\"data\", \"forestfires.csv\")) %&gt;% \n  clean_names() %&gt;% \n  mutate(month = as.factor(month),\n         day = as.factor(day)) %&gt;%\n  mutate(area = log(area + 1))\n\n#make fig corr map using ggcorrplot\nforest %&gt;% select(where(is.numeric)) %&gt;% \n  cor() %&gt;% \n  ggcorrplot(\n    method = \"circle\",\n    type='upper',\n    outline.col = \"black\",\n    legend.title = \"Correlation\" \n  ) +\n   labs(\n    title = \"Variables Correlation Matrix\")\n\n\n\n\n\nFigure 1. Correlation matrix heatmap. Red corresponds to a positive correlation while blue represents a negative correlation between the two variables. Darker colors indicate stronger correlations. Temperature has a strong negative correlation with relative humidity (rh) while duff moisture code (dmc) and drought code (dc) have a strong positive correlation.\n\n\n\n\n\n\nMethods\n\nSplit the data into training and testing sets.\n\n\nCode\n# Split the data into training and testing sets\nset.seed(123)\nforest_split &lt;- initial_split(forest, prop = 0.8, strata = area)\nforest_train &lt;- training(forest_split)\nforest_test &lt;- testing(forest_split)\n\n\nCreate a preprocessing recipe to handle zero-variance predictors and high correlations.\n\n\nCode\n# Create a recipe for preprocessing the data\nforest_recipe &lt;- recipe(area ~ ., data = forest_train) %&gt;%  \n  step_zv(all_predictors()) %&gt;%  \n  step_corr(all_numeric_predictors(), threshold = 0.9)\n\n\nDefine the Random Forest model and set tuning parameters.\n\n\nCode\n# Set engine\nforest_spec &lt;- rand_forest(mtry = tune(), trees = 500, min_n = tune()) %&gt;% \n  set_engine(\"ranger\") %&gt;% \n  set_mode(\"regression\")\n\n\nCreate a workflow by combining the preprocessing recipe and model.\n\n\nCode\n# Create a workflow\nforest_wf &lt;- workflow() %&gt;% \n  add_recipe(forest_recipe) %&gt;% \n  add_model(forest_spec)\n\n\nDefine a hyperparameter grid for tuning.\n\n\nCode\n# Create a grid of hyperparameters to tune\nforest_grid= expand_grid(\n  mtry = seq(1, 6, by=2),\n  min_n = seq(2, 8, by=2)\n)\n\n\nPerform cross-validation and tune the model using the defined grid.\n\n\nCode\n# Perform cross-validation\nforest_res &lt;- tune_grid(\n  forest_wf,\n  resamples = vfold_cv(forest_train, v = 10),\n  grid = forest_grid,\n  metrics = metric_set(mae, rmse, rsq),\n  control = control_grid(save_workflow = TRUE))\n\n\nSelect the best hyperparameters based on mean absolute error (MAE) and finalize the model.\n\n\nCode\n# Finalize model using mean absolute error metric\nforest_best &lt;- select_best(forest_res, metric='mae')\nforest_final &lt;- finalize_model(forest_spec, forest_best)\n\n\nFit the final model to the training data and evaluate it on the test set.\n\n\nCode\n# Fit the final model on the training data and evaluate on test set\nfinal_wf &lt;- workflow() %&gt;%\n  add_recipe(forest_recipe) %&gt;%\n  add_model(forest_final)\n\nfinal_res &lt;- final_wf %&gt;%\n  last_fit(forest_split, metrics = metric_set(mae))\n\n\nCollect the final predictions from the test set.\n\n\nCode\n# Collect the results\nfinal_predictions &lt;- final_res %&gt;%\n  collect_predictions()\n\nbest_mtry &lt;- forest_best$mtry\nbest_min_n &lt;- forest_best$min_n\n\nmetrics &lt;- final_res %&gt;%\n  collect_metrics()\n\nmae_value &lt;- mae(final_predictions, truth = area, estimate = .pred)\nrmse_value &lt;- rmse(final_predictions, truth = area, estimate = .pred)\n\n# Transform to compare to paper\nfinal_predictions_nonlog &lt;- final_predictions %&gt;%\n  mutate(\n    .pred = (exp(.pred)-1),\n    area = (exp(area)-1)\n  )\n\nmae_nonlog &lt;- mae(final_predictions_nonlog, truth = area, estimate = .pred)\nrmse_nonlog &lt;- rmse(final_predictions_nonlog, truth = area, estimate = .pred)\n\nresults_table &lt;- tibble(\n  `MAE (Test)` = mae_value$.estimate,\n  `MAE (Non-Log)` = mae_nonlog$.estimate,\n  `RMSE (Test)` = rmse_value$.estimate,\n  `RMSE (Non-Log)` = rmse_nonlog$estimate,\n  `Optimal mtry` = best_mtry,\n  `Optimal min_n` = best_min_n,\n  `Study MAE` = 13.31 \n)\n\nkable(results_table, caption = \"Random Forest Model Performance and Hyperparameters\") %&gt;% \n  kable_styling()\n\n\n\nRandom Forest Model Performance and Hyperparameters\n\n\nMAE (Test)\nMAE (Non-Log)\nRMSE (Test)\nOptimal mtry\nOptimal min_n\nStudy MAE\n\n\n\n\n1.075592\n10.38123\n1.336439\n1\n2\n13.31\n\n\n\n\n\n\n\n\n\nBy tuning mtry and min_n to minimize MAE, the model’s predictive accuracy improved, as seen in the reduction from 13.31 (Study MAE) to 10.38 (MAE Non-Log). This tuning helped to identify the optimal number of predictors to consider at each split and ensured that each decision tree captured meaningful patterns that avoided overfitting. The improvement indicates that the tuned hyperparameters led to better predictions by the model.\n\n\n\nCode\n# Plot variable importance\nforest_final %&gt;% \n  set_engine('ranger', importance = 'permutation') %&gt;% \n  fit(area ~ ., data = juice(prep(forest_recipe))) %&gt;%\n  vip(geom = \"point\", aesthetics = list(color = \"darkblue\", \n                                        size = 3, \n                                        alpha=0.5)) +\n  labs(title = \"Variable Importance Plot\",\n       x = \"Variable\",\n       y = \"Importance Score\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5, size = 16),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),\n  )\n\n\n\n\n\nFigure 2. Variable Importance Plot for Random Forest Model Predicting Burn Area. The plot displays the relative importance of each predictor variable in the model, with the importance scores calculated using permutation-based feature importance. Variables are ordered from least important to most important on the y-axis with their importance score on the x-axis highlighting which variables are most influential in predicting burn area.\n\n\n\n\n\n\nConclusions\n\nTuning the model on hyperparameters (e.g., mtry, min_n) resulted in a decrease in MAE from 13.31 to 10.43, indicating an improvement in predictive accuracy.\nThe variable importance plot highlights which predictors contribute most to the model’s predictive power. These variables are drought code, temperature, and month. Ecologically, these variables may have a bigger influence on fire and burn area compared to the other variables included in this analysis. Identifying and prioritizing key variables can reduce the number of features in the model without sacrificing accuracy, leading to a more efficient model.\nRain and relative humidity have the lowest variable importance scores, indicating that these factors contribute less to the model’s predictive power. While these variables may play a role in influencing burn area, their impact is less significant compared to other predictors in the model. These variables can be removed in future model iterations to reduce complexity and minimize overfitting."
  },
  {
    "objectID": "projects/2025-01-22-peru/index.html",
    "href": "projects/2025-01-22-peru/index.html",
    "title": "Analyzing temperature and precipitation in Peru from global climate earth observations",
    "section": "",
    "text": "Analyzing and Visualizing Temperature in Peru from 2010-2020\nCode for obtaining data through Google Earth Engine:\n\n\nCode\n#code for obtaining precipitation and temperature data from Google Earth Engine\n# ////////////////////////////////////////////////////////////\n# // visualize average temperature across Peru from 2010-2020:\n# ////////////////////////////////////////////////////////////\n# \n# //filter climate data to date range of interest:\n# var ERA5_2010s = ERA5.filterDate('2010-01-01', '2020-01-01');\n# \n# //select the temperature band of the images:\n# var ERA5_2010s_Temp = ERA5_2010s.select('temperature_2m');\n# \n# var ERA5_2010s_Precip = ERA5_2010s.select('total_precipitation_sum')\n# \n# //compute average temperature by pixel across the image collection,\n# //and clip resulting image to Peru:\n# var ERA5_2010s_Precip_Peru = ERA5_2010s_Precip.mean().clip(Peru);\n# \n# //convert Kelvin to Celsius across the average temperature image:\n# var Peru_Temp_C = ERA5_2010s_Temp_Peru.subtract(273.15);\n# \n# //add temperature image and Peru district shapefile to the map to visualize:\n# var styling = {color: 'black', fillColor: '00000000', width: 1};\n# Map.addLayer(Peru.style(styling));\n# Map.addLayer(Peru_Temp_C, {min:0, max:30, palette:['blue', 'limegreen', 'yellow', 'darkorange', 'red']});\n# \n# //////////////////////////////////////////////////////////////////\n# // visualize time series of temperature in Madre de Dios District:\n# //////////////////////////////////////////////////////////////////\n# \n# Map.addLayer(MDD); //use inspector to identify district to select\n# \n# //select Huepetuhe:\n# var Huepetuhe = MDD.filter('NOMBDIST == \"HUEPETUHE\"');\n# \n# //filter climate data to 2019:\n# var ERA5_2019 = ERA5.filterDate('2019-01-01', '2020-01-01');\n# \n# //select the temperature band of the images and convert to Celsius:\n# var ERA5_2019_Temp = ERA5_2019.select('temperature_2m');\n# \n# var ERA5_2019_Temp_C = ERA5_2019_Temp.map(function (image) {\n#   return image.subtract(273.15).copyProperties(image, ['system:time_start'])});\n# \n# //Define the chart and print it to the console:\n# var chart =\n#     ui.Chart.image\n#         .series({\n#           imageCollection: ERA5_2019_Temp_C,\n#           region: Huepetuhe, //reduce by Huepetuhe district in Madre de Dios\n#           reducer: ee.Reducer.mean(),\n#           scale: 11132, //scale of raster data\n#         })\n#         .setOptions({\n#           title: 'Average Temperature by Date',\n#           hAxis: {title: 'Date', titleTextStyle: {italic: false, bold: true}},\n#           vAxis: {\n#             title: 'Temperature (celsius)',\n#             titleTextStyle: {italic: false, bold: true}\n#           },\n#           lineWidth: 2,\n#         });\n# print(chart);\n# \n# \n# /////////////////////////////////////////////////////\n# // Export temperature time series by district in MDD:\n# /////////////////////////////////////////////////////\n# \n# //reduce 2010s temperature by MDD regions:\n# var ERA5_2010s_Temp_C = ERA5_2010s_Temp.map(function (image) {\n#   return image.subtract(273.15).copyProperties(image, ['system:time_start'])});\n# \n# var reduced_ERA5_2010s = ERA5_2010s_Temp_C.map(function(image){\n#   return image.reduceRegions({\n#     collection: MDD, \n#     reducer: ee.Reducer.mean(), \n#     scale: 11132\n#   });\n# }).flatten();\n# \n# Export.table.toDrive({\n#   collection: reduced_ERA5_2010s,\n#   description:'MDD_Temperature',\n#   selectors: ['system:index', 'IDDIST',   'mean'],\n#   fileFormat: 'csv'\n# });\n# \n# \n# ///////////////////////////////////////////////////////////////\n# // Export avg. temperature by district across Peru for mapping:\n# ///////////////////////////////////////////////////////////////\n# \n# //reduce avg. temperature by Peru districts:\n# \n# var reduced_Peru_Temp_C = Peru_Temp_C.reduceRegions({\n#     collection: Peru, \n#     reducer: ee.Reducer.mean(), \n#     scale: 11132\n#   });\n# \n# Export.table.toDrive({\n#   collection: reduced_Peru_Temp_C,\n#   description:'Peru_Temperature',\n#   selectors: ['system:index', 'IDDIST',   'mean'],\n#   fileFormat: 'csv'\n# });\n#         \n# ////////////////////////////////////////////////////////////\n# // visualize average temperature across Peru from 2010-2020:\n# ////////////////////////////////////////////////////////////\n# \n# //filter climate data to date range of interest:\n# var ERA5_2010s = ERA5.filterDate('2010-01-01', '2020-01-01');\n# \n# //select the temperature band of the images:\n# var ERA5_2010s_Temp = ERA5_2010s.select('temperature_2m');\n# \n# var ERA5_2010s_Precip = ERA5_2010s.select('total_precipitation_sum')\n# \n# //compute average temperature by pixel across the image collection,\n# //and clip resulting image to Peru:\n# var ERA5_2010s_Precip_Peru = ERA5_2010s_Precip.mean().clip(Peru);\n# \n# //convert Kelvin to Celsius across the average temperature image:\n# var Peru_Temp_C = ERA5_2010s_Temp_Peru.subtract(273.15);\n# \n# //add temperature image and Peru district shapefile to the map to visualize:\n# var styling = {color: 'black', fillColor: '00000000', width: 1};\n# Map.addLayer(Peru.style(styling));\n# Map.addLayer(Peru_Temp_C, {min:0, max:30, palette:['blue', 'limegreen', 'yellow', 'darkorange', 'red']});\n# \n# //////////////////////////////////////////////////////////////////\n# // visualize time series of temperature in Madre de Dios District:\n# //////////////////////////////////////////////////////////////////\n# \n# Map.addLayer(MDD); //use inspector to identify district to select\n# \n# //select Huepetuhe:\n# var Huepetuhe = MDD.filter('NOMBDIST == \"HUEPETUHE\"');\n# \n# //filter climate data to 2019:\n# var ERA5_2019 = ERA5.filterDate('2019-01-01', '2020-01-01');\n# \n# //select the temperature band of the images and convert to Celsius:\n# var ERA5_2019_Temp = ERA5_2019.select('temperature_2m');\n# \n# var ERA5_2019_Temp_C = ERA5_2019_Temp.map(function (image) {\n#   return image.subtract(273.15).copyProperties(image, ['system:time_start'])});\n# \n# //Define the chart and print it to the console:\n# var chart =\n#     ui.Chart.image\n#         .series({\n#           imageCollection: ERA5_2019_Temp_C,\n#           region: Huepetuhe, //reduce by Huepetuhe district in Madre de Dios\n#           reducer: ee.Reducer.mean(),\n#           scale: 11132, //scale of raster data\n#         })\n#         .setOptions({\n#           title: 'Average Temperature by Date',\n#           hAxis: {title: 'Date', titleTextStyle: {italic: false, bold: true}},\n#           vAxis: {\n#             title: 'Temperature (celsius)',\n#             titleTextStyle: {italic: false, bold: true}\n#           },\n#           lineWidth: 2,\n#         });\n# print(chart);\n# \n# \n# /////////////////////////////////////////////////////\n# // Export temperature time series by district in MDD:\n# /////////////////////////////////////////////////////\n# \n# //reduce 2010s temperature by MDD regions:\n# var ERA5_2010s_Temp_C = ERA5_2010s_Temp.map(function (image) {\n#   return image.subtract(273.15).copyProperties(image, ['system:time_start'])});\n# \n# var reduced_ERA5_2010s = ERA5_2010s_Temp_C.map(function(image){\n#   return image.reduceRegions({\n#     collection: MDD, \n#     reducer: ee.Reducer.mean(), \n#     scale: 11132\n#   });\n# }).flatten();\n# \n# Export.table.toDrive({\n#   collection: reduced_ERA5_2010s,\n#   description:'MDD_Temperature',\n#   selectors: ['system:index', 'IDDIST',   'mean'],\n#   fileFormat: 'csv'\n# });\n# \n# \n# ///////////////////////////////////////////////////////////////\n# // Export avg. temperature by district across Peru for mapping:\n# ///////////////////////////////////////////////////////////////\n# \n# //reduce avg. temperature by Peru districts:\n# \n# var reduced_Peru_Temp_C = Peru_Temp_C.reduceRegions({\n#     collection: Peru, \n#     reducer: ee.Reducer.mean(), \n#     scale: 11132\n#   });\n# \n# Export.table.toDrive({\n#   collection: reduced_Peru_Temp_C,\n#   description:'Peru_Temperature',\n#   selectors: ['system:index', 'IDDIST',   'mean'],\n#   fileFormat: 'csv'\n# });\n\n\n\n\nCode\nPeru_dist &lt;- read_sf(here(\"data\", \"per_admbnda_adm3_2018.shp\"))\n\nPeru_dist_temp &lt;- read.csv(here(\"data\", \"Peru_Temperature.csv\"))\n\nPeru_dist_temp$IDDIST &lt;- str_pad(Peru_dist_temp$IDDIST, 6, pad = \"0\") # pad with leading 0 to match IDDIST in shapefile\n\n#clean data\nPeru_dist_temp$system.index &lt;- NULL\n\n#merge data\nPeru_dist_temp_merge &lt;- merge(Peru_dist, Peru_dist_temp, by=c(\"IDDIST\"), all.x=T, all.y=T)\n\nvalid_values_temp &lt;- Peru_dist_temp_merge$mean[!is.na(Peru_dist_temp_merge$mean)]\n\n#map data\nggplot(data = Peru_dist_temp_merge) +\n  geom_sf(aes(fill = mean), color = \"black\", size = 0.3) +  \n  scale_fill_distiller(name = \"Temperature (C)\", \n                       palette = \"YlOrRd\", \n                       direction = 1) + \n  labs(title = \"Temperature Distribution Across Districts in Peru\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nCode\n##Code for creating an interactive map using leaflet (too computational for website rendering)\n\n#pal &lt;- colorNumeric(palette = \"YlOrRd\", domain = Peru_dist_temp_merge$mean)\n\n#leaflet(Peru_dist_temp_merge) %&gt;%\n#  addTiles() %&gt;%\n#  addPolygons(fillColor = ~pal(mean),  # color scale applied to 'mean' temperature values\n#              fillOpacity = 1, \n#              color = \"black\", \n#              weight = 0.5,\n#              popup = ~paste(\"District:\", ADM3_ES, \"&lt;br&gt;\", \"Temperature (C):\", round(mean, 2))) %&gt;%\n#  addLegend(pal = pal, values = valid_values_temp, \n#             na.label = NULL,\n#            title = \"Temperature (C)\", opacity = 1)\n\n\n\nTemperature in Peru is highest in the Amazon Forest region and along the coast. Lowest temperatures are observed at high elevations in the Andes Mountain range.\n\n\n\nCode\ntemp_19 &lt;- read.csv(here(\"data\", \"temperature_19.csv\"))\n\ncolnames(temp_19)[colnames(temp_19) == \"system.time_start\"] &lt;- \"date\"\n\ntemp_19 &lt;- temp_19 %&gt;%\n  mutate(date = as.Date(date, format = \"%b %d, %Y\"))\n\ntemp_19$month &lt;- format(temp_19$date, \"%B\")\n\nggplot(temp_19, aes(x = date, y = temperature_2m)) +\n  geom_line(size = 1.2, color=\"darkorange2\") +\n  labs(title = \"2019 Average Daily Temperature in Peru\", \n       x = \"Month\", \n       y = \"Temperature (°C)\") +\n  scale_x_date(\n    date_breaks = \"1 month\",  # Breaks at every month\n    date_labels = \"%B\"       # Display full month names\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nAverage daily temperature displays seasonal patterns within the year. Warmer temperatures between January-April mark the summer season, while a drop in temperatures during July and August mark the peak of winter.\n\n\n\nAnalyzing and Visualizing Precipitation in Peru from 2010-2020\n\n\nCode\nPeru_dist_precip &lt;- read.csv(here(\"data\", \"Peru_Precipitation.csv\"))\n\nPeru_dist_precip$IDDIST &lt;- str_pad(Peru_dist_precip$IDDIST, 6, pad = \"0\") #pad with leading 0 to match IDDIST in shapefile\n\n#adjust precipitation to be in mm\nPeru_dist_precip$mean &lt;- Peru_dist_precip$mean*1000\n\n#merge data\nPeru_dist_precip_merge &lt;- merge(Peru_dist, Peru_dist_precip, by=c(\"IDDIST\"), all.x=T, all.y=T)\n\nbreaks &lt;- pretty(Peru_dist_precip_merge$mean, n = 20)\n\nvalid_values &lt;- Peru_dist_precip_merge$mean[!is.na(Peru_dist_precip_merge$mean)]\n\n#map data\nggplot(data = Peru_dist_precip_merge) +\n  geom_sf(aes(fill = mean), color = \"black\", size = 0.3) +\n  scale_fill_distiller(name = \"Precipitation (mm)\", \n                       palette = \"YlGnBu\", \n                       direction = 1) +\n  labs(title = \"Precipitation Distribution Across Districts in Peru\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\nCode\n##Code for creating an interactive map using leaflet (too computational for website rendering)\n\n#pal &lt;- colorNumeric(palette = \"YlGnBu\", domain = Peru_dist_precip_merge$mean)\n\n#leaflet(Peru_dist_precip_merge) %&gt;%\n# addTiles() %&gt;%\n#  addPolygons(fillColor = ~pal(mean),  # color scale applied to 'mean' temperature values\n#              fillOpacity = 1, \n#              color = \"black\", \n#              weight = 0.5,\n#              popup = ~paste(\"District:\", ADM3_ES, \"&lt;br&gt;\", \"Precipitation (mm):\", round(mean, 2))) %&gt;%\n#  addLegend(pal = pal, values = valid_values, \n#             na.label = NULL,\n#            title = \"Precipitation (mm)\", opacity = 1)\n\n\n\nAverage annual precipitation in Peru from 2010-2020 is notably highest in the District of Camanti. High average annual precipitation is also observed in the Amazon Forest region. Low levels of precipitation are observed along the coast and southern region of Peru.\n\n\n\nCode\nprecip_19 &lt;- read.csv(here(\"data\", \"precipitation_19.csv\"))\n\ncolnames(precip_19)[colnames(precip_19) == \"system.time_start\"] &lt;- \"date\"\n\nprecip_19 &lt;- precip_19 %&gt;%\n  mutate(date = as.Date(date, format = \"%b %d, %Y\"))\n\nprecip_19$month &lt;- format(precip_19$date, \"%B\")\n\nggplot(precip_19, aes(x = date, y = total_precipitation_sum)) +\n  geom_line(size = 1.2, color=\"cornflowerblue\") +\n  labs(title = \"2019 Average Daily Precipitation in Peru\", \n       x = \"Month\", \n       y = \"Precipitation (mm)\") +\n  scale_x_date(\n    date_breaks = \"1 month\",  # Breaks at every month\n    date_labels = \"%B\"       # Display full month names\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nAverage daily precipitation displays seasonal patterns within the year. High precipitation days between October to December mark the wet season, while the dry season is observed around June-September"
  },
  {
    "objectID": "projects/2022-12-05-buttefire/index.html",
    "href": "projects/2022-12-05-buttefire/index.html",
    "title": "Planning for wildfire resilience in Butte County, CA",
    "section": "",
    "text": "Click here for optimal viewing of the full StoryMap"
  },
  {
    "objectID": "projects/2025-03-11-timeseries/index.html",
    "href": "projects/2025-03-11-timeseries/index.html",
    "title": "Assessing and Forecasting Willamette Falls Fish Passage",
    "section": "",
    "text": "Introduction & Data Summary\nFish passage is a critical component of river ecosystem health, ensuring migratory species can access spawning and rearing habitats essential for their survival. In the Pacific Northwest, species like coho salmon (Oncorhynchus kisutch), jack coho (precocious male coho that return earlier than typical adults), and steelhead trout (Oncorhynchus mykiss) rely on unobstructed passage to complete their life cycles. At Willamette Falls in Oregon, one of the largest natural waterfalls in the region, fish passage is especially important due to the historical and ongoing impacts of barriers such as dams.\n\n\n\n\n\nFish ladder at Fall Creek Dam in Oregon (Photo by Kristyna Wentz-Graff/OPB)\n\n\n\n\n\n\n\nCoho salmon swimming upstream (Photo by Chuck Haney)\n\n\n\n\nThe Willamette Falls Fish Ladder is an effort by the Oregon Department of Fish and Wildlife to support fish migration. It is composed of three individual fish ladders that merge into a single exit point above Willamette Falls. Biologists have visually counted observations of fish passing through the fishway since 2001. The dataset used in this analysis records counts for several fish species between 2001 and 2010 at the station.\nData Citation: Columbia River DART. DART Adult Passage Counts (Willamette Falls, 2001-2010). https://www.cbr.washington.edu/dart/query/adult_graph_text. Accessed January 25, 2023.\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(here)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(paletteer)\nlibrary(janitor)\nlibrary(patchwork)\nlibrary(scales)\n\n\n\n\nPurpose & Methods\nThis analysis aims to assess and forecast fish passage time series data collected at the Willamette Falls fish ladder on the Willamette River in Oregon. The analysis focuses on three select focal species: Coho salmon, Jack coho salmon, and Steelhead trout. The following procedure outlines the methods of this analysis:\n\nConvert data frame into a time series data frame.\nPlot the time series to assess general temporal trends in fish passage for each species.\nCreate a seasonplot to assess fish passage trends throughout years across the study period for each species.\nAggregate fish counts by year and plot annual fish counts for each species to understand annual fish passage trends.\nForecast salmon runs using Holt-Winters exponential smoothing.\n\n\n\nCode\n# Load data, replace NA with 0, and convert to tsibble\nfish_ts &lt;- read_csv(here(\"data\", \"willamette_fish_passage.csv\")) %&gt;% \n  clean_names() %&gt;% \n  mutate_all(~replace(., is.na(.), 0)) %&gt;% \n  select(date, coho, jack_coho, steelhead) %&gt;% \n  mutate(date = lubridate::mdy(date)) %&gt;%\n  as_tsibble(key = NULL, \n             index = date)\n  \n\n# Pivot data longer\nfish_long &lt;- fish_ts %&gt;% \n  pivot_longer(-date, \n               names_to = \"species\", \n               values_to = \"count\")\n\n\n\n\nResults\n\nTime SeriesSeasonplotAnnual CountsForecast\n\n\n\n\nCode\n# Plot time series and facet wrap by species\nfish_long %&gt;% \n  ggplot(aes(x = date, y = count, color = species)) +\n  geom_line() +\n  scale_color_manual(values = c('#BA7999FF', '#59629BFF', '#015B58FF')) +\n  facet_wrap(~species, \n             nrow = 3, \n             labeller = labeller(species = \n                                   c(\"coho\" = \"Coho\",\n                                     \"jack_coho\" = \"Jack Coho\",\n                                     \"steelhead\" = \"Steelhead\")),\n             scales = \"free_y\") +\n  labs(title = \"Adult Fish Passage at Willamette Falls 2001-2010\",\n       x = \"Date\",\n       y = \"Count of Fish\") +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nFigure 1. Fish Passage Counts Time Series. Counts of fish passing through the Willamette Falls fish ladder from 2001-2010 by species.\n\n\n\n\n\n\nAll three fish species pass through Willamette Falls at relatively regular intervals annually.\nPeak Coho and Jack coho passage align at the same time, within fairly narrow windows.\nSteelhead passage occurs over a wider time window, with variable, less-defined peaks compared to the sharp peaks observed in Coho and Jack Coho counts.\n\n\n\n\n\n\nCode\n# Season plot\nfish_long %&gt;%\n  gg_season(y = count, pal = paletteer_d(\"PNWColors::Starfish\")) +\n  facet_wrap(~species, \n             nrow = 3, \n             labeller = labeller(species = \n                                   c(\"coho\" = \"Coho\",\n                                     \"jack_coho\" = \"Jack Coho\",\n                                     \"steelhead\" = \"Steelhead\")),\n             scales = \"free_y\") +\n  labs(x = \"Date\",\n       y = \"Count of Fish\",\n       title=\"Seasonal Trends in Adult Fish Passage at Willamette Falls\") +\n  scale_y_continuous(labels = scales::comma) +\n    theme_minimal()\n\n\n\n\n\nFigure 2. Fish Passage Counts Seasonplot. Counts of fish passage by species throughout the year from 2001-2010. Counts in earlier years are green and blue and more recent years are in purple and pink.\n\n\n\n\n\n\nPeak passage times for Coho and Jack Coho occur annually during the fall. There are lower and narrower peaks in earlier years compared to more recent years.\nSteelhead passage follows a different seasonal pattern, with variable peaks from winter through mid-summer, with counts leveling off during the late summer and fall. Higher passage counts occurred during earlier years, with more recent years observing less steelhead at Willamette Falls.\n\n\n\n\n\n\nCode\n# Group data by fish species and year\nfish_ts_year &lt;- fish_long %&gt;% \n  index_by(year = ~year(.)) %&gt;% \n  group_by(species, year) %&gt;%\n  summarise(annual_count = sum(count))\n\n# Plot annual fish passage by species\nfish_ts_year %&gt;% \n  ggplot(aes(x = year, y = annual_count, color = species)) +\n  geom_line() +\n  geom_point() +\n  scale_color_manual(values = c('#BA7999FF', '#59629BFF', '#015B58FF')) +\n  facet_wrap(~species, \n             nrow = 3, \n             labeller = labeller(species = \n                                   c(\"coho\" = \"Coho\",\n                                     \"jack_coho\" = \"Jack Coho\",\n                                     \"steelhead\" = \"Steelhead\")),\n             scales = \"free_y\") +\n  labs(title = \"Annual Counts of Adult Fish Passage at Willamette Falls 2001-2010\",\n       x = \"Year\",\n       y = \"Count of Fish\") +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +\n  scale_y_continuous(labels = scales::comma) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nFigure 3. Annual Fish Counts 2001-2010. Counts of fish passage by species and year.\n\n\n\n\n\n\nCoho numbers fluctuate over the years with a notable significant increase between 2008 and 2009.\nJack coho numbers also fluctuate, with a declining trend from 2002-2005. Jack Coho numbers saw a significant increase between 2007 and 2008 before the observed increase in Coho the following year. However, it is unclear from the data alone whether Coho and Jack coho species influence one another’s population dynamics.\nSteelhead numbers show a general decline throughout the study period. However, counts of steelhead increase in 2009, which may be an indicator of population recovery efforts for the endangered species. Still, continued monitoring over time is necessary to draw meaningful conclusions.\n\n\n\n\n\n\nCode\n# Get data into year and month form\nfish_month &lt;- fish_long %&gt;% \n  index_by(yr_mo = ~yearmonth(.)) %&gt;%  \n  group_by(species, yr_mo) %&gt;% \n  summarize(count = round(sum(count, na.rm = TRUE)))  %&gt;%  \n  ungroup()\n\n# Create forecast model for each species\nsteelhead_fit &lt;- fish_month %&gt;%\n  filter(species == 'steelhead') %&gt;%\n  model(\n    ets = ETS(count ~  trend(method = \"A\") + season(method = \"A\"))\n  )\n\ncoho_fit &lt;- fish_month %&gt;%\n  filter(species == 'coho') %&gt;%\n  model(\n    ets = ETS(count ~  trend(method = \"A\") + season(method = \"A\"))\n  )\n  \njack_fit &lt;- fish_month %&gt;%\n  filter(species == 'jack_coho') %&gt;%\n  model(\n    ets = ETS(count ~  trend(method = \"A\") + season(method = \"A\"))\n  )\n\n# Forecast using the model 5 years into the future:\nsteelhead_forecast &lt;- steelhead_fit %&gt;% \n  forecast(h = \"5 years\", level = c(80, 95)) %&gt;% \n  hilo(level = c(80, 95)) %&gt;% \n mutate(\n    lower_80 = str_split(`80%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[1], \"\\\\[|\\\\]\", \"\")))), \n    upper_80 = str_split(`80%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[2], \"\\\\]\", \"\")))),\n    lower_95 = str_split(`95%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[1], \"\\\\[|\\\\]\", \"\")))), \n    upper_95 = str_split(`95%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[2], \"\\\\]\", \"\")))),\n  ) %&gt;% \n  clean_names() %&gt;% \n  select(-x80_percent, -x95_percent) %&gt;% \n  rename(\n    count = mean,\n    old_count = count    \n  ) %&gt;%\n  mutate(count = round(count, 0))\n\ncoho_forecast &lt;- coho_fit %&gt;% \n  forecast(h = \"5 years\", level = c(80, 95)) %&gt;% \n  hilo(level = c(80, 95)) %&gt;% \n  mutate(\n    lower_80 = str_split(`80%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[1], \"\\\\[|\\\\]\", \"\")))), \n    upper_80 = str_split(`80%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[2], \"\\\\]\", \"\")))),\n    lower_95 = str_split(`95%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[1], \"\\\\[|\\\\]\", \"\")))), \n    upper_95 = str_split(`95%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[2], \"\\\\]\", \"\")))),\n  ) %&gt;% \n  clean_names() %&gt;% \n  select(-x80_percent, -x95_percent) %&gt;% \n  rename(\n    count = mean,\n    old_count = count    \n  ) %&gt;%\n  mutate(count = round(count, 0))\n\njack_forecast &lt;- jack_fit %&gt;% \n  forecast(h = \"5 years\", level = c(80, 95)) %&gt;% \n  hilo(level = c(80, 95)) %&gt;% \n  mutate(\n    lower_80 = str_split(`80%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[1], \"\\\\[|\\\\]\", \"\")))), \n    upper_80 = str_split(`80%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[2], \"\\\\]\", \"\")))),\n    lower_95 = str_split(`95%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[1], \"\\\\[|\\\\]\", \"\")))), \n    upper_95 = str_split(`95%`, \",\") %&gt;%\n      sapply(function(x) as.numeric(str_trim(str_replace(x[2], \"\\\\]\", \"\")))),\n  ) %&gt;% \n  clean_names() %&gt;% \n  select(-x80_percent, -x95_percent) %&gt;% \n  rename(\n    count = mean,\n    old_count = count    \n  ) %&gt;%\n  mutate(count = round(count, 0))\n\n# Combine dataframes for plotting\nsteelhead_forecast_df &lt;- bind_rows(\n  fish_month %&gt;% mutate(source = \"Observed\"),\n  steelhead_forecast %&gt;% mutate(source = \"Forecasted\")\n)\n\ncoho_forecast_df &lt;- bind_rows(\n  fish_month %&gt;% mutate(source = \"Observed\"),\n  coho_forecast %&gt;% mutate(source = \"Forecasted\")\n)\n\njack_forecast_df &lt;- bind_rows(\n  fish_month %&gt;% mutate(source = \"Observed\"),\n  jack_forecast %&gt;% mutate(source = \"Forecasted\")\n)\n\n# Plot for coho\np1 &lt;- ggplot(coho_forecast_df, aes(x = yr_mo, y = count, color = source)) +\n  geom_ribbon(aes(ymin = lower_95, ymax = upper_95, fill = \"95% CI\"), \n              alpha = 1, color = NA) +  \n  geom_ribbon(aes(ymin = lower_80, ymax = upper_80, fill = \"80% CI\"), \n              alpha = 1, color = NA) +\n  geom_line() + \n  labs(title = \"Coho\") +\n  scale_color_manual(values = c(\"Observed\" = \"black\", \"Forecasted\" = \"#BA7999FF\")) +\n  scale_fill_manual(values = c(\"80% CI\" = \"#d2a4ba\", \"95% CI\" = \"#e9d1dc\")) +\n  theme_minimal() +\n  theme(legend.title = element_blank(),\n    axis.title.x = element_blank(), \n    axis.title.y = element_blank() )\n\n# Plot for jack coho\np2 &lt;- ggplot(jack_forecast_df, aes(x = yr_mo, y = count, color = source)) +\n  geom_ribbon(aes(ymin = lower_95, ymax = upper_95, fill = \"95% CI\"), \n              alpha = 1, color = NA) +  \n  geom_ribbon(aes(ymin = lower_80, ymax = upper_80, fill = \"80% CI\"), \n              alpha = 1, color = NA) +\n  geom_line() + \n  labs(title = \"Jack Coho\", y = \"Count\") +\n  scale_color_manual(values = c(\"Observed\" = \"black\", \"Forecasted\" = \"#59629BFF\")) +\n  scale_fill_manual(values = c(\"80% CI\" = \"#8c94bd\", \"95% CI\" = \"#c4c9de\")) +\n  theme_minimal() +\n  theme(legend.title = element_blank(),\n        axis.title.x = element_blank(),)\n\n# Plot for steelhead\np3 &lt;- ggplot(steelhead_forecast_df, aes(x = yr_mo, y = count, color = source)) +\n  geom_ribbon(aes(ymin = lower_95, ymax = upper_95, fill = \"95% CI\"), \n              alpha = 1, color = NA) +  \n  geom_ribbon(aes(ymin = lower_80, ymax = upper_80, fill = \"80% CI\"), \n              alpha = 1, color = NA) +\n  geom_line() + \n  labs(title = \"Steelhead\", x = \"Date\") +\n  scale_color_manual(values = c(\"Observed\" = \"black\", \"Forecasted\" = \"#015B58FF\")) +\n  scale_fill_manual(values = c(\"80% CI\" = \"#7ca19e\", \"95% CI\" = \"#afc6c4\")) +\n  theme_minimal() +\n  theme(legend.title = element_blank(),\n        axis.title.y = element_blank(),)\n\n# Combine the plots vertically and set the layout\nforecast_plot &lt;- p1 / p2 / p3 + \n  plot_layout(guides = \"collect\") +\n  plot_annotation(title = \"Five-year fish count forecast\")\n\n# Print the combined plot\nprint(forecast_plot)\n\n\n\n\n\n\n\n\n\n\n\nThe forecast model predicts similar overall patterns over the next 5 years in this data time frame. However, the magnitude and granularity of the predicted counts is simplified.\nIn the case of Jack Coho, forecasted fish counts did not resemble observed trends, with predicted counts significantly decreasing over the next 5 years.\nGiven these results, a Holt-Winters forecast method is not very useful in predicting fish counts. This is due to variable trends within the data and inability of the model to account for complex ecological dynamics that influence fish count."
  },
  {
    "objectID": "projects/2024-09-10-nff/index.html",
    "href": "projects/2024-09-10-nff/index.html",
    "title": "Telling the story of drought and watershed restoration in the Colorado River Basin",
    "section": "",
    "text": "Click here for optimal viewing of the full StoryMap"
  },
  {
    "objectID": "projects/2024-03-12-sedgwick/index.html",
    "href": "projects/2024-03-12-sedgwick/index.html",
    "title": "Conceptual prescribed burn planning at Sedgwick Reserve",
    "section": "",
    "text": "Background\nWith growing interest in the use of controlled burning as an effective land management strategy, there is also a growing need to train prescribed fire practitioners. In response to this, The Nature Conservancy (TNC), in partnership with the U.S. Forest Service hosts Prescribed Fire Training Exchanges (TREX) that provide the necessary workforce training and learning experience to safely conduct prescribed burns.\nSedgwick Reserve, one of the 42 reserves in the statewide UC Natural Reserve System, spans 6,000 acres of coastal sage scrub and oak woodland commmunities. Situated in the wildland urban interface of the Santa Ynez Foothills, the reserve offers a unique opportunity to unite fire practitioners and researchers around intentional fire to reduce fire risk and understand the ecological effects of controlled fire on the landscape. There have been two TREX’s at the reserve led by TNC Fire Management and the Santa Barbara County Fire Department, with plans for future burns.\n\n\n\nFigure 1. Map of the Sedgwick Reserve boundary and location.\n\n\n\n\nMethods\nThis project aims to identify suitable locations in the reserve for a future prescribed burn through a raster suitability analysis. This framework for geospatial burn planning has been used by land management agencies like the National Park Service to select critical areas for burning. I identified the most suitable areas for a future prescribed burn by weighing factors such as slope, vegetation, soils, geology, historical fire perimeters, proximity to roads, and building infrastructure.\n\n\n\nFigure 2. Workflow and methods schematic.\n\n\n\n\nResults\n\n \n\n\nFigure 3. Weighted opportunities factors and suitability scores (A) shows suitable areas in the northern region of the reserve. Weighted constraint factors (B) indicates the southern region of the reserve, where infrastructure is located, is highly unsuitable.\n\n Combining the opportunities and constraints, I generated the composite suitability map below.\n\n\n\nFigure 4. This final composite suitability map combines the opportunities and constraints to reveal areas with the highest suitability scores, outlined in red.\n\n\nIt is important to note that this analysis is not comprehensive, but can serve as a starting point for prescribed burn planning. Prescribed burn planning is a dynamic process that takes into account numerous factors such as weather, safety, and potential hazards that can’t be determined from this data. Consultation with fire practitioners, fire departments, land managers, and researchers is required in addition to a suitability analysis. Being able to visualize suitable areas is important for planning management efforts at landscape scales, but expert opinion and on the ground knowledge is critical to informing these decisions."
  },
  {
    "objectID": "projects/2024-08-30-nff/index.html",
    "href": "projects/2024-08-30-nff/index.html",
    "title": "Tracking and visualizing watershed restoration projects across the Colorado River Basin",
    "section": "",
    "text": "Colorado River Basin Restoration Project Dashboard\nThis interactive dashboard dynamically tracks project metrics and provides summaries of the restoration methods for staff, funders, and folks curious about NFF’s watershed work to visualize and track project goals."
  },
  {
    "objectID": "projects/2025-02-14-pca/index.html",
    "href": "projects/2025-02-14-pca/index.html",
    "title": "Principal Component Analysis of Environmental Variables and Global Tree Canopy Cover",
    "section": "",
    "text": "Dataset and Analysis Overview\nThe dataset used in this analysis contains the following 28 environmental variables aggregated at the country level (all data was acquired through Google Earth Engine and averaged at a 10km resolution):\n\n\n\n\n\n\n\n\n\n\nTravel time to cities (min)\n\n\nSlope\n\n\nElevation (m)\n\n\nAspect\n\n\n\n\nAverage cloudy days per year (days)\n\n\nPercent cropland cover (%)\n\n\nPercent tree canopy cover (%)\n\n\nIsothermality\n\n\n\n\nPrecipitation of driest month (mm)\n\n\nPrecipitation of wettest month (mm)\n\n\nPrecipitation of driest quarter (mm)\n\n\nPrecipitation of wettest quarter (mm)\n\n\n\n\nPrecipitation of coldest quarter (mm)\n\n\nPrecipitation of warmest quarter (mm)\n\n\nPrecipitation seasonality (mm)\n\n\nAnnual precipitation (mm)\n\n\n\n\nMean temperature of coldest quarter (degC)\n\n\nMean temperature of warmest quarter (degC)\n\n\nMin temperature of coldest month (degC)\n\n\nMax temperature of warmest month (degC)\n\n\n\n\nMean temperature of wettest quarter (degC)\n\n\nMean temperature of driest quarter (degC)\n\n\nTemperature annual range (%)\n\n\nTemperature mean annual (degC)\n\n\n\n\nTemperature seasonality (degC)\n\n\nMean diurnal range (degC)\n\n\nMean wind speed (m/s)\n\n\nCountry\n\n\n\n\nA principal components analysis (PCA) can be used to simplify the complexity of multivariate data by transforming it into fewer dimensions while explaining as much of the variance as possible. Each observation in this dataset is one country and its associated environmental variables listed in the table above. The purpose of this analysis is to explore the relationships between tree canopy cover and various environmental factors across different countries. By examining variables such as mean annual temperature, temperature seasonality, precipitation during the warmest quarter, cloudiness, and elevation, I aim to identify patterns and trends that influence tree canopy cover. This analysis will help better understand how environmental conditions shape canopy cover and provide insights into potential environmental drivers of vegetation distribution.\nData Citation: Venter, Zander. (2018). Environmental variables for world countries. Retrieved 2025-02-02 from https://www.kaggle.com/datasets/zanderventer/environmental-variables-for-world-countries.\n\n\nCode\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(ggfortify)\nlibrary(kableExtra)\n\n#create table outlining pseudocode\npseudo_df &lt;- data.frame(\n  Steps = c(\"Read in and clean data\", \n                  \"Create histograms to visualize data distribution of each variable\", \n                  \"Determine the optimal number of components to retain\", \n                  \"Run the PCA\", \n                  \"Plot the results in a biplot\"))\n\npseudo_df %&gt;% kable(\"html\", escape = FALSE) %&gt;%\n  kable_styling(bootstrap_options = c(\"hover\")) %&gt;%\n  pack_rows(\"1. Explore Data\", 1, 2) %&gt;%\n  pack_rows(\"2. Principal Components Analysis\", 3, 4) %&gt;%\n  pack_rows(\"3. Visualize the results\", 5, 5) \n\n\n\n\n\nSteps\n\n\n\n\n1. Explore Data\n\n\nRead in and clean data\n\n\nCreate histograms to visualize data distribution of each variable\n\n\n2. Principal Components Analysis\n\n\nDetermine the optimal number of components to retain\n\n\nRun the PCA\n\n\n3. Visualize the results\n\n\nPlot the results in a biplot\n\n\n\n\n\n\n\n\n\nData Exploration\nFor this analysis, I selected focal variables that are generally important determinants of tree canopy cover. To visualize the structure of each variable in the dataset, I created histograms of each variable.\n\n\nCode\n#read in the data\nworld_env &lt;- read_csv(here(\"data\", \"world_env_vars.csv\"))\n\n#clean the data and select focal variables\nworld_env_clean &lt;- world_env %&gt;% \n  clean_names() %&gt;% \n  drop_na() %&gt;% \n  select(tree_canopy_cover, temp_mean_annual, temp_seasonality, rain_warmest_quart, rain_mean_annual, cloudiness, elevation)\n\n#pivot data longer for use in histogram visualization\nworld_env_long &lt;- world_env_clean %&gt;% \n  pivot_longer(names_to = 'name', values_to = 'value', where(is.numeric))\n\n#exploratory data visualization\nggplot(world_env_long, aes(x = value)) +\n  geom_histogram(fill='#79ACBD') +\n  facet_wrap(~ name, scales = 'free_x')\n\n\n\n\n\nFigure 1: Histograms showing the distribution of seven selected environmental variables in the dataset.\n\n\n\n\n\n\nPrincipal Components Analysis\n\n\nCode\n#create the pcs object\nworld_env_pca &lt;- world_env_clean %&gt;% \n  select(where(is.numeric)) %&gt;%\n  prcomp(scale = TRUE)\n\n#view weightings for each principal component\nworld_env_pca$rotation\n\n\n                          PC1         PC2         PC3          PC4         PC5\ntree_canopy_cover   0.4529758  0.21666554  0.07681649  0.216834626 -0.75624375\ntemp_mean_annual    0.2360685 -0.66074177 -0.25583257  0.094083041 -0.04566213\ntemp_seasonality   -0.3819649  0.37935803  0.35359574  0.409404488 -0.07941572\nrain_warmest_quart  0.4345505  0.19015356 -0.03792685  0.574699738  0.60463010\nrain_mean_annual    0.4953388  0.08396304 -0.03304056  0.065135635 -0.05893986\ncloudiness          0.3706554  0.38176430  0.17387582 -0.664823588  0.21512173\nelevation          -0.1469942  0.42849935 -0.87798408 -0.002499778 -0.06614133\n                          PC6         PC7\ntree_canopy_cover  -0.1486317 -0.31773400\ntemp_mean_annual    0.5937210 -0.28071406\ntemp_seasonality    0.6405031 -0.03157817\nrain_warmest_quart -0.1368901 -0.24284319\nrain_mean_annual    0.2554264  0.82069411\ncloudiness          0.3361570 -0.29217895\nelevation           0.1348209 -0.03697799\n\n\nCode\n#create fields for scree plot dataframe\npc_names &lt;- colnames(world_env_pca$rotation)\nsd_vec &lt;- world_env_pca$sdev\nvar_vec &lt;- sd_vec^2\n\n#creat data frame for scree plot\npct_expl_df &lt;- data.frame(v = var_vec,\n                          pct_v = var_vec / sum(var_vec),\n                          pc = pc_names)\n\n#make a scree plot\nggplot(pct_expl_df, aes(x = pc, y = v)) +\n  geom_col(fill=\"#79ACBD\") +\n  geom_text(aes(label = scales::percent(pct_v)), vjust = -0.5, nudge_y = .002) +\n  labs(x = 'Principal component', y = 'Variance explained') +\n  theme_minimal()\n\n\n\n\n\nFigure 2: The scree plot displays Principal Components (PC) 1-7, where PC1 explains 53.92% of the total variance and PC2 explains 22.51%. This significant decrease in explained variance from PC1 to PC2 suggests that subsequent components may contribute less meaningfully to the overall variance.\n\n\n\n\n\n\nCode\nautoplot(world_env_pca,\n        data = world_env_clean,\n        loadings = TRUE,\n        loadings.label = TRUE,\n        loadings.colour = \"black\",\n        loadings.label.colour = \"black\",\n        loadings.label.vjust = -0.5\n        ) +\n  theme_minimal()\n\n\n\n\n\nFigure 3: Principal Components Analysis (PCA) biplot illustrating correlations between global tree canopy cover and environmental variables. The arrows indicate the loading for each variable in the dimensions of PC1 and PC2 and the points indicate different countries.\n\n\n\n\n\nFrom the results of the PCA, I observed that tree canopy cover, precipitation of the warmest quarter, mean annual precipitation, and cloudiness are highly positively correlated. Mean annual temperature is uncorrelated with these variables and temperature seasonality and elevation are both negatively correlated with these variables. This suggests that tree canopy cover is more influenced by moisture availability (precipitation and cloudiness) than fluctuations in temperature.\nTree canopy cover may be more dependent on the amount of water available in the environment, which directly affects tree health, growth, and density. Precipitation is a key factor for vegetation growth, especially in areas where water availability limits canopy expansion. While temperature may still play a role in influencing tree canopy cover (e.g., through seasonal growth patterns or temperature extremes), it appears that precipitation plays a more significant role in shaping tree canopy cover across the studied regions. This relationship could suggest that areas with more rainfall are likely to support denser or healthier tree canopies. Conversely, regions with less precipitation might have sparse or stressed tree canopy cover, even if temperature conditions are favorable.\nIn the context of climate change, shifts in precipitation patterns could have a larger impact on tree canopy cover than changes in temperature, emphasizing the importance of managing water resources for forest and canopy preservation. Further analysis and added data could group countries by hemisphere or dominant biome to reveal additional trends among the data points."
  },
  {
    "objectID": "projects/2024-09-27-kudzu/index.html",
    "href": "projects/2024-09-27-kudzu/index.html",
    "title": "Identifying forest areas threatened by invasive Kudzu under climate change",
    "section": "",
    "text": "Background\nKudzu (Pueraria montana) is a perennial vine native to eastern Asia which has become invasive in the United States. It is able to grow extremely quickly and outcompete native vegetation. This exacts an ecological and economic toll, particularly on timber forests which suffer productivity losses due to kudzu growth (Herron et al., 2020). Currently found across much of the southeastern U.S., kudzu may continue to spread north and west as climate change creates more favorable environmental conditions (“Kudzu: The Invasive Vine That Ate the South,” 2019).\n\n\nProblem\nGiven the ecologically and economically taxing impact of Kudzu on forest productivity and native biodiversity, it is important to identify areas that should be restored in the face of climate change. Utilizing species distribution models can inform how Kudzu will spread under certain climate scenarios and what areas restoration projects should be planned for.\n\n\nApproach\nWe used Maxent within the R package Wallace to create species distribution models (SDMs) of kudzu in the present day and under future climate-and-socioeconomic scenarios (SSPs). We obtained 10,000 occurrence points from GBIF for kudzu, then selected down to only those points within the contiguous United States (~5,000) and spatially partitioned them into four groups for model training. We selected a variety of WorldClim Bioclim variables (Table 1) for precipitation and temperature based upon a brief review of relevant literature and knowledge of kudzu’s ecological niche (Callen & Miller, 2015; Kovach-Hammons et al., 2023). We extracted this data from 10,000 background points within a 5 degree buffer of our occurrence points. We used the Maxent algorithm to model current habitat suitability for kudzu, setting linear and quadratic feature classes to account for linear and non-linear relationships. We set the regularization parameter as 1.5 to avoid over-fitting our model and to determine a simpler complexity. Clamping was set as ‘true’ to constrain our variables within the focal range and parallel processing was set as ‘false.’ Using the MIROC6 climate model, we then transferred our model to a future scenario of moderate climate-and-socioeconomic change (SSP 370) for the years 2041-2060.\nIn ArcGIS Pro, we processed our SDMs along with the 2019 NLCD data (30m resolution, contiguous U.S.) to find forested areas that overlapped with current and predicted kudzu presence. We used the SDMs for the present day, and for SSP 370 in 2041-2060. We ensured all our data layers were in the Albers equal-area conic projection to preserve area for our calculations, and resampled our data to a 1km resolution for faster processing time. We reclassified and isolated just the forested areas from NLCD (encompassing deciduous, evergreen, and mixed forests) and intersected these with areas of kudzu presence (defined as SDM probabilities &gt; 50%).\n\n\nResults\nWe found a total forested area of 496,114 km2 was currently at risk of kudzu occupation, mainly across the southeastern U.S. (Figure 1). The area between Charlotte, NC and Knoxville, TN is particularly concentrated with current suitable forest habitat for kudzu. In 2041-2060 under SSP 370, we found that a forested area of 555,508 km2 would be at risk of kudzu occupation (Figure 2). While still mainly predicted to be within the southeastern U.S., kudzu may also be found as far north as Pittsburgh and Boston in this future scenario.\n\n \n\n\nFigure 1. Suitable Forest Habitat For Kudzu. Panel A shows forested areas of the southeastern United States that are currently suitable habitat for kudzu in green. Panel B shows forested areas of the eastern United States that may be suitable habitat for kudzu under SSP 370 during the years 2041-2060. All other forested areas are shown in gray.\n\n\n\nConclusion\nEstimated to cost greater than $500 million annually in damages and loss of forest productivity, kudzu is expected to spread and cause increases in economic losses under climate change (Blaustein, 2001). Due to kudzu’s significant economic and ecological impact on forests in the southeastern U.S., it is necessary to identify suitable areas under climate change scenarios to target invasive species mitigation strategically. The northward spread of kudzu highlights opportunities to integrate invasive species prevention measures in northern areas while also highlighting restoration opportunities in regions that are deemed to be no longer suitable for kudzu under future climate change. Restoration and prevention measures will be costly, and given the economic toll kudzu has already enacted on forest ecosystems, it will require proper prioritization, communication, and stakeholder engagement to successfully complete these types of projects."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Assessing and Forecasting Willamette Falls Fish Passage\n\n\n\nR\n\n\nModeling\n\n\n\nInvestigation of time series data to understand and predict trends in fish passage\n\n\n\nThuy-Tien Bui\n\n\nMar 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting forest burn area using random forests\n\n\n\nR\n\n\nModeling\n\n\nFire\n\n\nClimate\n\n\n\nA random forest decision tree analysis for predicting the amount of area burned by wildfire based on a set of environmental variables\n\n\n\nThuy-Tien Bui\n\n\nMar 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrincipal Component Analysis of Environmental Variables and Global Tree Canopy Cover\n\n\n\nR\n\n\nModeling\n\n\nClimate\n\n\n\nUsing PCA to determine the relationship between tree canopy cover and various environmental variables\n\n\n\nThuy-Tien Bui\n\n\nFeb 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying plant species using binary logistic regression\n\n\n\nR\n\n\nModeling\n\n\n\nAn analysis of palmetto species identification based on survival, growth, and biomass estimates\n\n\n\nThuy-Tien Bui\n\n\nFeb 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing temperature and precipitation in Peru from global climate earth observations\n\n\n\nR\n\n\nGIS\n\n\nRemote Sensing\n\n\nClimate\n\n\n\nAn analysis of temperature and precipitation trends using ERA5 precipitation and temperature data obtained from Google Earth Engine\n\n\n\nThuy-Tien Bui\n\n\nJan 22, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifying forest areas threatened by invasive Kudzu under climate change\n\n\n\nGIS\n\n\nForestry\n\n\nClimate\n\n\n\nA climate change suitability analysis of Kudzu habitat in the southeastern United States\n\n\n\nThuy-Tien Bui, Olivia Hemond\n\n\nSep 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTelling the story of drought and watershed restoration in the Colorado River Basin\n\n\n\nGIS\n\n\nCommunication\n\n\nWatersheds\n\n\n\nAn interactive StoryMap created for the National Forest Foundation’s Colorado River Restoration Initiative\n\n\n\nThuy-Tien Bui\n\n\nSep 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTracking and visualizing watershed restoration projects across the Colorado River Basin\n\n\n\nGIS\n\n\nWatersheds\n\n\n\nA project dashboard tool created for the National Forest Foundation’s Colorado River Restoration Initiative\n\n\n\nThuy-Tien Bui\n\n\nAug 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConceptual prescribed burn planning at Sedgwick Reserve\n\n\n\nGIS\n\n\nFire\n\n\nForestry\n\n\n\nA suitability analysis for future prescribed fire sites at Sedgwick Reserve\n\n\n\nThuy-Tien Bui\n\n\nMar 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlanning for wildfire resilience in Butte County, CA\n\n\n\nGIS\n\n\nFire\n\n\nForestry\n\n\n\nA suitability analysis for wildfire risk interventions in Butte County\n\n\n\nThuy-Tien Bui, Caitlin Grace, Julia Marks\n\n\nDec 5, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Litter removal increases plant diversity by promoting both native and exotic forbs in heavily invaded coastal sage scrub in Southern California, U.S.A.\n\n\n\n\n\nA research article on native plant diversity published in the Journal of Restoration Ecology \n\n\n\n\n\nDec 16, 2024\n\n\nAdvyth Ramachandran, Caryn Iwanaga, Michael Fugate, Jared Huxley, Annika Rose-Person, Rhea Amatya, Thuy-Tien Bui, Marko Spasojevic\n\n\n\n\n\n\n\n\n\n\n\n\nTraditional Ecological Knowledge, Indigenous Burning Controversies, and Bringing Back ‘Good Fire’ By the Amah Mustun Tribal Band\n\n\n\n\n\nA research essay on traditional ecological knowledge originally published in Perennial: The Undergraduate Environmental Journal of Berkeley \n\n\n\n\n\nSep 30, 2023\n\n\nThuy-Tien Bui\n\n\n\n\n\n\n\n\n\n\n\n\nAnthropogenic Climate Change in Point Reyes National Seashore, California, USA\n\n\n\n\n\nA comprehensive climate change assessment report originally published to the University of California, Berkeley Institute for Parks, People, and Biodiversity \n\n\n\n\n\nMay 26, 2023\n\n\nThuy-Tien Bui\n\n\n\n\n\n\n\n\n\n\n\n\nWhy the insect crisis should really bug us\n\n\n\n\n\nAn op-ed on insect loss originally published in Perennial: The Undergraduate Environmental Journal of Berkeley \n\n\n\n\n\nJun 6, 2022\n\n\nThuy-Tien Bui\n\n\n\n\n\n\n\n\n\n\n\n\nHow we can restore an ecosystem engineer that fights climate change\n\n\n\n\n\nAn article on coastal resilience originally published in Perennial: The Undergraduate Environmental Journal of Berkeley \n\n\n\n\n\nJan 14, 2022\n\n\nThuy-Tien Bui\n\n\n\n\n\n\nNo matching items"
  }
]